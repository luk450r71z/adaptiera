from typing import Dict, Any
from langchain_core.messages import HumanMessage, AIMessage
from langchain_groq import ChatGroq
import os
from dotenv import load_dotenv
from agents.state import ConversationState
from agents.utils import load_questions_from_file, save_responses_to_file, simulate_email_send_simple

# Cargar variables de entorno desde .env
load_dotenv()


def initialize_conversation_node(state: ConversationState) -> ConversationState:
    """
    Nodo inicial que carga las preguntas y prepara la conversaci√≥n.
    """
    print("üöÄ Inicializando conversaci√≥n...")
    
    # Cargar preguntas desde archivo
    questions = load_questions_from_file("data/questions.json")
    state.pending_questions = questions
    state.current_question_index = 0
    
    if questions:
        state.current_question = questions[0]
        
        # Mensaje de bienvenida
        welcome_message = AIMessage(content="""
¬°Hola! Soy el asistente de RRHH de Adaptiera. 
Voy a realizarte algunas preguntas para conocerte mejor.
Responde con la mayor sinceridad posible.

Empecemos:
""")
        state.messages.append(welcome_message)
        
        # Primera pregunta
        question_message = AIMessage(content=state.current_question)
        state.messages.append(question_message)
    
    return state


def process_user_response_node(state: ConversationState) -> ConversationState:
    """
    Nodo que procesa la respuesta del usuario y decide si es satisfactoria.
    """
    print("ü§î Procesando respuesta del usuario...")
    
    # Obtener la √∫ltima respuesta del usuario
    last_message = state.messages[-1] if state.messages else None
    
    if not isinstance(last_message, HumanMessage):
        print("‚ö†Ô∏è No se encontr√≥ respuesta del usuario")
        return state
    
    user_response = last_message.content
    current_question = state.current_question
    
    # Configurar el LLM (Groq)
    groq_api_key = os.getenv("GROQ_API_KEY")
    if not groq_api_key:
        print("‚ö†Ô∏è GROQ_API_KEY no configurada, usando l√≥gica simple")
        # L√≥gica simple sin LLM (m√°s permisiva)
        is_satisfactory = len(user_response.strip()) > 3
        clarification_reason = "Por favor, proporciona una respuesta m√°s detallada" if not is_satisfactory else None
    else:
        # Usar Groq para evaluar la respuesta (modelo actualizado)
        llm = ChatGroq(api_key=groq_api_key, model="llama-3.3-70b-versatile")
        
        evaluation_prompt = f"""
        Eval√∫a si la siguiente respuesta es satisfactoria para la pregunta planteada:
        
        Pregunta: {current_question}
        Respuesta: {user_response}
        
        Responde SOLO con:
        - "SATISFACTORIA" si la respuesta proporciona informaci√≥n b√°sica relevante a la pregunta
        - "NECESITA_CLARIFICACION: [raz√≥n]" si la respuesta est√° completamente vac√≠a, es irrelevante o muy confusa
        
        S√© PERMISIVO en tu evaluaci√≥n. Acepta respuestas que tengan al menos alguna relaci√≥n con la pregunta, 
        incluso si son breves o no muy detalladas. Solo solicita clarificaci√≥n si la respuesta realmente 
        no tiene sentido o est√° completamente fuera de tema.
        """
        
        try:
            evaluation = llm.invoke(evaluation_prompt).content.strip()
            
            if evaluation.startswith("SATISFACTORIA"):
                is_satisfactory = True
                clarification_reason = None
            else:
                is_satisfactory = False
                clarification_reason = evaluation.replace("NECESITA_CLARIFICACION:", "").strip()
        except Exception as e:
            print(f"Error al evaluar con Groq: {e}")
            # Fallback a l√≥gica simple (m√°s permisiva)
            is_satisfactory = len(user_response.strip()) > 3
            clarification_reason = "Por favor, proporciona una respuesta m√°s detallada" if not is_satisfactory else None
    
    # Actualizar estado
    if is_satisfactory:
        # Guardar respuesta satisfactoria
        state.user_responses[current_question] = user_response
        state.needs_clarification = False
        state.clarification_reason = None
        print(f"‚úÖ Respuesta aceptada para: {current_question}")
    else:
        state.needs_clarification = True
        state.clarification_reason = clarification_reason
        print(f"‚ùì Necesita clarificaci√≥n: {clarification_reason}")
    
    return state


def clarification_node(state: ConversationState) -> ConversationState:
    """
    Nodo que solicita aclaraci√≥n cuando la respuesta no es satisfactoria.
    """
    print("üîÑ Solicitando aclaraci√≥n...")
    
    clarification_message = AIMessage(content=f"""
Me gustar√≠a que puedas ampliar tu respuesta anterior.
{state.clarification_reason}

Por favor, proporciona m√°s detalles sobre: {state.current_question}
""")
    
    state.messages.append(clarification_message)
    return state


def next_question_node(state: ConversationState) -> ConversationState:
    """
    Nodo que avanza a la siguiente pregunta.
    """
    print("‚û°Ô∏è Avanzando a la siguiente pregunta...")
    
    state.current_question_index += 1
    
    if state.current_question_index < len(state.pending_questions):
        # Hay m√°s preguntas
        state.current_question = state.pending_questions[state.current_question_index]
        
        next_question_message = AIMessage(content=f"""
Perfecto, gracias por tu respuesta.

Siguiente pregunta:
{state.current_question}
""")
        state.messages.append(next_question_message)
    else:
        # No hay m√°s preguntas, marcar como completa
        state.conversation_complete = True
        state.current_question = None
        
        completion_message = AIMessage(content="""
¬°Excelente! Hemos terminado con todas las preguntas.
Ahora voy a procesar tu informaci√≥n y enviar un resumen.
""")
        state.messages.append(completion_message)
    
    return state


def finalize_conversation_node(state: ConversationState) -> ConversationState:
    """
    Nodo final que guarda las respuestas y env√≠a el correo.
    """
    print("üèÅ Finalizando conversaci√≥n...")
    
    # Guardar respuestas en archivo
    save_success = save_responses_to_file(state.user_responses, "data/user_responses.json")
    
    # Enviar correo (simulado por ahora)
    email_success = simulate_email_send_simple(state.user_responses)
    
    if save_success and email_success:
        final_message = AIMessage(content="""
¬°Muchas gracias por tu tiempo! 

‚úÖ Tus respuestas han sido guardadas correctamente
‚úÖ Se ha enviado un resumen por correo electr√≥nico

Nuestro equipo de RRHH revisar√° tu informaci√≥n y se pondr√° en contacto contigo pronto.

¬°Que tengas un excelente d√≠a!
""")
    else:
        final_message = AIMessage(content="""
Gracias por completar la entrevista. 
Hubo algunos problemas t√©cnicos al procesar tu informaci√≥n, 
pero nuestro equipo se pondr√° en contacto contigo pronto.
""")
    
    state.messages.append(final_message)
    return state


def decision_node(state: ConversationState) -> str:
    """
    Funci√≥n de decisi√≥n que determina el siguiente paso en el flujo.
    Esta funci√≥n NO modifica el estado, solo retorna la decisi√≥n.
    """
    print("üéØ Tomando decisi√≥n sobre el siguiente paso...")
    
    # Si la conversaci√≥n est√° completa, ir al nodo final
    if state.conversation_complete:
        print("   ‚Üí Conversaci√≥n completa, finalizando...")
        return "finalize"
    
    # Si necesita aclaraci√≥n, ir al nodo de aclaraci√≥n
    if state.needs_clarification:
        print("   ‚Üí Necesita aclaraci√≥n...")
        return "clarify"
    
    # Si hay un mensaje del usuario pendiente de procesar
    if state.messages and isinstance(state.messages[-1], HumanMessage):
        print("   ‚Üí Procesando respuesta del usuario...")
        return "process_response"
    
    # Si no hay pregunta actual, ir a la siguiente
    if not state.current_question:
        print("   ‚Üí Avanzando a siguiente pregunta...")
        return "next_question"
    
    # Por defecto, esperar respuesta del usuario
    print("   ‚Üí Esperando respuesta del usuario...")
    return "wait_for_user"


def dummy_decision_node(state: ConversationState) -> ConversationState:
    """
    Nodo dummy que no hace nada, solo para mantener la estructura del grafo.
    La l√≥gica real est√° en la funci√≥n decision_node que se usa para routing.
    """
    return state 